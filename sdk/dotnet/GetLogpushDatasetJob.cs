// *** WARNING: this file was generated by pulumi-language-dotnet. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

using System;
using System.Collections.Generic;
using System.Collections.Immutable;
using System.Threading.Tasks;
using Pulumi.Serialization;

namespace Pulumi.Cloudflare
{
    public static class GetLogpushDatasetJob
    {
        /// <summary>
        /// ## Example Usage
        /// 
        /// ```csharp
        /// using System.Collections.Generic;
        /// using System.Linq;
        /// using Pulumi;
        /// using Cloudflare = Pulumi.Cloudflare;
        /// 
        /// return await Deployment.RunAsync(() =&gt; 
        /// {
        ///     var exampleLogpushDatasetJob = Cloudflare.GetLogpushDatasetJob.Invoke(new()
        ///     {
        ///         DatasetId = "gateway_dns",
        ///         AccountId = "account_id",
        ///         ZoneId = "zone_id",
        ///     });
        /// 
        /// });
        /// ```
        /// </summary>
        public static Task<GetLogpushDatasetJobResult> InvokeAsync(GetLogpushDatasetJobArgs? args = null, InvokeOptions? options = null)
            => global::Pulumi.Deployment.Instance.InvokeAsync<GetLogpushDatasetJobResult>("cloudflare:index/getLogpushDatasetJob:getLogpushDatasetJob", args ?? new GetLogpushDatasetJobArgs(), options.WithDefaults());

        /// <summary>
        /// ## Example Usage
        /// 
        /// ```csharp
        /// using System.Collections.Generic;
        /// using System.Linq;
        /// using Pulumi;
        /// using Cloudflare = Pulumi.Cloudflare;
        /// 
        /// return await Deployment.RunAsync(() =&gt; 
        /// {
        ///     var exampleLogpushDatasetJob = Cloudflare.GetLogpushDatasetJob.Invoke(new()
        ///     {
        ///         DatasetId = "gateway_dns",
        ///         AccountId = "account_id",
        ///         ZoneId = "zone_id",
        ///     });
        /// 
        /// });
        /// ```
        /// </summary>
        public static Output<GetLogpushDatasetJobResult> Invoke(GetLogpushDatasetJobInvokeArgs? args = null, InvokeOptions? options = null)
            => global::Pulumi.Deployment.Instance.Invoke<GetLogpushDatasetJobResult>("cloudflare:index/getLogpushDatasetJob:getLogpushDatasetJob", args ?? new GetLogpushDatasetJobInvokeArgs(), options.WithDefaults());

        /// <summary>
        /// ## Example Usage
        /// 
        /// ```csharp
        /// using System.Collections.Generic;
        /// using System.Linq;
        /// using Pulumi;
        /// using Cloudflare = Pulumi.Cloudflare;
        /// 
        /// return await Deployment.RunAsync(() =&gt; 
        /// {
        ///     var exampleLogpushDatasetJob = Cloudflare.GetLogpushDatasetJob.Invoke(new()
        ///     {
        ///         DatasetId = "gateway_dns",
        ///         AccountId = "account_id",
        ///         ZoneId = "zone_id",
        ///     });
        /// 
        /// });
        /// ```
        /// </summary>
        public static Output<GetLogpushDatasetJobResult> Invoke(GetLogpushDatasetJobInvokeArgs args, InvokeOutputOptions options)
            => global::Pulumi.Deployment.Instance.Invoke<GetLogpushDatasetJobResult>("cloudflare:index/getLogpushDatasetJob:getLogpushDatasetJob", args ?? new GetLogpushDatasetJobInvokeArgs(), options.WithDefaults());
    }


    public sealed class GetLogpushDatasetJobArgs : global::Pulumi.InvokeArgs
    {
        /// <summary>
        /// The Account ID to use for this endpoint. Mutually exclusive with the Zone ID.
        /// </summary>
        [Input("accountId")]
        public string? AccountId { get; set; }

        /// <summary>
        /// Name of the dataset. A list of supported datasets can be found on the [Developer Docs](https://developers.cloudflare.com/logs/reference/log-fields/).
        /// Available values: "access*requests", "audit*logs", "audit*logs*v2", "biso*user*actions", "casb*findings", "device*posture*results", "dlp*forensic*copies", "dns*firewall*logs", "dns*logs", "email*security*alerts", "firewall*events", "gateway*dns", "gateway*http", "gateway*network", "http*requests", "magic*ids*detections", "nel*reports", "network*analytics*logs", "page*shield*events", "sinkhole*http*logs", "spectrum*events", "ssh*logs", "workers*trace*events", "zaraz*events", "zero*trust*network*sessions".
        /// </summary>
        [Input("datasetId")]
        public string? DatasetId { get; set; }

        /// <summary>
        /// The Zone ID to use for this endpoint. Mutually exclusive with the Account ID.
        /// </summary>
        [Input("zoneId")]
        public string? ZoneId { get; set; }

        public GetLogpushDatasetJobArgs()
        {
        }
        public static new GetLogpushDatasetJobArgs Empty => new GetLogpushDatasetJobArgs();
    }

    public sealed class GetLogpushDatasetJobInvokeArgs : global::Pulumi.InvokeArgs
    {
        /// <summary>
        /// The Account ID to use for this endpoint. Mutually exclusive with the Zone ID.
        /// </summary>
        [Input("accountId")]
        public Input<string>? AccountId { get; set; }

        /// <summary>
        /// Name of the dataset. A list of supported datasets can be found on the [Developer Docs](https://developers.cloudflare.com/logs/reference/log-fields/).
        /// Available values: "access*requests", "audit*logs", "audit*logs*v2", "biso*user*actions", "casb*findings", "device*posture*results", "dlp*forensic*copies", "dns*firewall*logs", "dns*logs", "email*security*alerts", "firewall*events", "gateway*dns", "gateway*http", "gateway*network", "http*requests", "magic*ids*detections", "nel*reports", "network*analytics*logs", "page*shield*events", "sinkhole*http*logs", "spectrum*events", "ssh*logs", "workers*trace*events", "zaraz*events", "zero*trust*network*sessions".
        /// </summary>
        [Input("datasetId")]
        public Input<string>? DatasetId { get; set; }

        /// <summary>
        /// The Zone ID to use for this endpoint. Mutually exclusive with the Account ID.
        /// </summary>
        [Input("zoneId")]
        public Input<string>? ZoneId { get; set; }

        public GetLogpushDatasetJobInvokeArgs()
        {
        }
        public static new GetLogpushDatasetJobInvokeArgs Empty => new GetLogpushDatasetJobInvokeArgs();
    }


    [OutputType]
    public sealed class GetLogpushDatasetJobResult
    {
        /// <summary>
        /// The Account ID to use for this endpoint. Mutually exclusive with the Zone ID.
        /// </summary>
        public readonly string? AccountId;
        /// <summary>
        /// Name of the dataset. A list of supported datasets can be found on the [Developer Docs](https://developers.cloudflare.com/logs/reference/log-fields/).
        /// Available values: "access*requests", "audit*logs", "audit*logs*v2", "biso*user*actions", "casb*findings", "device*posture*results", "dlp*forensic*copies", "dns*firewall*logs", "dns*logs", "email*security*alerts", "firewall*events", "gateway*dns", "gateway*http", "gateway*network", "http*requests", "magic*ids*detections", "nel*reports", "network*analytics*logs", "page*shield*events", "sinkhole*http*logs", "spectrum*events", "ssh*logs", "workers*trace*events", "zaraz*events", "zero*trust*network*sessions".
        /// </summary>
        public readonly string Dataset;
        /// <summary>
        /// Name of the dataset. A list of supported datasets can be found on the [Developer Docs](https://developers.cloudflare.com/logs/reference/log-fields/).
        /// Available values: "access*requests", "audit*logs", "audit*logs*v2", "biso*user*actions", "casb*findings", "device*posture*results", "dlp*forensic*copies", "dns*firewall*logs", "dns*logs", "email*security*alerts", "firewall*events", "gateway*dns", "gateway*http", "gateway*network", "http*requests", "magic*ids*detections", "nel*reports", "network*analytics*logs", "page*shield*events", "sinkhole*http*logs", "spectrum*events", "ssh*logs", "workers*trace*events", "zaraz*events", "zero*trust*network*sessions".
        /// </summary>
        public readonly string DatasetId;
        /// <summary>
        /// Uniquely identifies a resource (such as an s3 bucket) where data. will be pushed. Additional configuration parameters supported by the destination may be included.
        /// </summary>
        public readonly string DestinationConf;
        /// <summary>
        /// Flag that indicates if the job is enabled.
        /// </summary>
        public readonly bool Enabled;
        /// <summary>
        /// If not null, the job is currently failing. Failures are usually. repetitive (example: no permissions to write to destination bucket). Only the last failure is recorded. On successful execution of a job the error*message and last*error are set to null.
        /// </summary>
        public readonly string ErrorMessage;
        /// <summary>
        /// This field is deprecated. Please use `max_upload_*` parameters instead. . The frequency at which Cloudflare sends batches of logs to your destination. Setting frequency to high sends your logs in larger quantities of smaller files. Setting frequency to low sends logs in smaller quantities of larger files.
        /// Available values: "high", "low".
        /// </summary>
        public readonly string Frequency;
        /// <summary>
        /// Unique id of the job.
        /// </summary>
        public readonly int Id;
        /// <summary>
        /// The kind parameter (optional) is used to differentiate between Logpush and Edge Log Delivery jobs (when supported by the dataset).
        /// Available values: "", "edge".
        /// </summary>
        public readonly string Kind;
        /// <summary>
        /// Records the last time for which logs have been successfully pushed. If the last successful push was for logs range 2018-07-23T10:00:00Z to 2018-07-23T10:01:00Z then the value of this field will be 2018-07-23T10:01:00Z. If the job has never run or has just been enabled and hasn't run yet then the field will be empty.
        /// </summary>
        public readonly string LastComplete;
        /// <summary>
        /// Records the last time the job failed. If not null, the job is currently. failing. If null, the job has either never failed or has run successfully at least once since last failure. See also the error_message field.
        /// </summary>
        public readonly string LastError;
        /// <summary>
        /// This field is deprecated. Use `output_options` instead. Configuration string. It specifies things like requested fields and timestamp formats. If migrating from the logpull api, copy the url (full url or just the query string) of your call here, and logpush will keep on making this call for you, setting start and end times appropriately.
        /// </summary>
        public readonly string LogpullOptions;
        /// <summary>
        /// The maximum uncompressed file size of a batch of logs. This setting value must be between `5 MB` and `1 GB`, or `0` to disable it. Note that you cannot set a minimum file size; this means that log files may be much smaller than this batch size.
        /// </summary>
        public readonly int MaxUploadBytes;
        /// <summary>
        /// The maximum interval in seconds for log batches. This setting must be between 30 and 300 seconds (5 minutes), or `0` to disable it. Note that you cannot specify a minimum interval for log batches; this means that log files may be sent in shorter intervals than this.
        /// </summary>
        public readonly int MaxUploadIntervalSeconds;
        /// <summary>
        /// The maximum number of log lines per batch. This setting must be between 1000 and 1,000,000 lines, or `0` to disable it. Note that you cannot specify a minimum number of log lines per batch; this means that log files may contain many fewer lines than this.
        /// </summary>
        public readonly int MaxUploadRecords;
        /// <summary>
        /// Optional human readable job name. Not unique. Cloudflare suggests. that you set this to a meaningful string, like the domain name, to make it easier to identify your job.
        /// </summary>
        public readonly string Name;
        /// <summary>
        /// The structured replacement for `logpull_options`. When including this field, the `logpull_option` field will be ignored.
        /// </summary>
        public readonly Outputs.GetLogpushDatasetJobOutputOptionsResult OutputOptions;
        /// <summary>
        /// The Zone ID to use for this endpoint. Mutually exclusive with the Account ID.
        /// </summary>
        public readonly string? ZoneId;

        [OutputConstructor]
        private GetLogpushDatasetJobResult(
            string? accountId,

            string dataset,

            string datasetId,

            string destinationConf,

            bool enabled,

            string errorMessage,

            string frequency,

            int id,

            string kind,

            string lastComplete,

            string lastError,

            string logpullOptions,

            int maxUploadBytes,

            int maxUploadIntervalSeconds,

            int maxUploadRecords,

            string name,

            Outputs.GetLogpushDatasetJobOutputOptionsResult outputOptions,

            string? zoneId)
        {
            AccountId = accountId;
            Dataset = dataset;
            DatasetId = datasetId;
            DestinationConf = destinationConf;
            Enabled = enabled;
            ErrorMessage = errorMessage;
            Frequency = frequency;
            Id = id;
            Kind = kind;
            LastComplete = lastComplete;
            LastError = lastError;
            LogpullOptions = logpullOptions;
            MaxUploadBytes = maxUploadBytes;
            MaxUploadIntervalSeconds = maxUploadIntervalSeconds;
            MaxUploadRecords = maxUploadRecords;
            Name = name;
            OutputOptions = outputOptions;
            ZoneId = zoneId;
        }
    }
}
