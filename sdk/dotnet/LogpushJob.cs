// *** WARNING: this file was generated by pulumi-language-dotnet. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

using System;
using System.Collections.Generic;
using System.Collections.Immutable;
using System.Threading.Tasks;
using Pulumi.Serialization;

namespace Pulumi.Cloudflare
{
    /// <summary>
    /// ## Example Usage
    /// 
    /// ## Import
    /// 
    /// ```sh
    /// $ pulumi import cloudflare:index/logpushJob:LogpushJob example '&lt;{accounts|zones}/{account_id|zone_id}&gt;/&lt;job_id&gt;'
    /// ```
    /// </summary>
    [CloudflareResourceType("cloudflare:index/logpushJob:LogpushJob")]
    public partial class LogpushJob : global::Pulumi.CustomResource
    {
        /// <summary>
        /// The Account ID to use for this endpoint. Mutually exclusive with the Zone ID.
        /// </summary>
        [Output("accountId")]
        public Output<string?> AccountId { get; private set; } = null!;

        /// <summary>
        /// Name of the dataset. A list of supported datasets can be found on the [Developer Docs](https://developers.cloudflare.com/logs/reference/log-fields/).
        /// Available values: "access*requests", "audit*logs", "biso*user*actions", "casb*findings", "device*posture*results", "dlp*forensic*copies", "dns*firewall*logs", "dns*logs", "email*security*alerts", "firewall*events", "gateway*dns", "gateway*http", "gateway*network", "http*requests", "magic*ids*detections", "nel*reports", "network*analytics*logs", "page*shield*events", "sinkhole*http*logs", "spectrum*events", "ssh*logs", "workers*trace*events", "zaraz*events", "zero*trust*network*sessions".
        /// </summary>
        [Output("dataset")]
        public Output<string> Dataset { get; private set; } = null!;

        /// <summary>
        /// Uniquely identifies a resource (such as an s3 bucket) where data will be pushed. Additional configuration parameters supported by the destination may be included.
        /// </summary>
        [Output("destinationConf")]
        public Output<string> DestinationConf { get; private set; } = null!;

        /// <summary>
        /// Flag that indicates if the job is enabled.
        /// </summary>
        [Output("enabled")]
        public Output<bool?> Enabled { get; private set; } = null!;

        /// <summary>
        /// If not null, the job is currently failing. Failures are usually repetitive (example: no permissions to write to destination bucket). Only the last failure is recorded. On successful execution of a job the error*message and last*error are set to null.
        /// </summary>
        [Output("errorMessage")]
        public Output<string> ErrorMessage { get; private set; } = null!;

        /// <summary>
        /// The filters to select the events to include and/or remove from your logs. For more information, refer to [Filters](https://developers.cloudflare.com/logs/reference/filters/).
        /// </summary>
        [Output("filter")]
        public Output<string?> Filter { get; private set; } = null!;

        /// <summary>
        /// This field is deprecated. Please use `max_upload_*` parameters instead. The frequency at which Cloudflare sends batches of logs to your destination. Setting frequency to high sends your logs in larger quantities of smaller files. Setting frequency to low sends logs in smaller quantities of larger files.
        /// Available values: "high", "low".
        /// </summary>
        [Output("frequency")]
        public Output<string> Frequency { get; private set; } = null!;

        /// <summary>
        /// The kind parameter (optional) is used to differentiate between Logpush and Edge Log Delivery jobs. Currently, Edge Log Delivery is only supported for the `http_requests` dataset.
        /// Available values: "edge".
        /// </summary>
        [Output("kind")]
        public Output<string> Kind { get; private set; } = null!;

        /// <summary>
        /// Records the last time for which logs have been successfully pushed. If the last successful push was for logs range 2018-07-23T10:00:00Z to 2018-07-23T10:01:00Z then the value of this field will be 2018-07-23T10:01:00Z. If the job has never run or has just been enabled and hasn't run yet then the field will be empty.
        /// </summary>
        [Output("lastComplete")]
        public Output<string> LastComplete { get; private set; } = null!;

        /// <summary>
        /// Records the last time the job failed. If not null, the job is currently failing. If null, the job has either never failed or has run successfully at least once since last failure. See also the error_message field.
        /// </summary>
        [Output("lastError")]
        public Output<string> LastError { get; private set; } = null!;

        /// <summary>
        /// This field is deprecated. Use `output_options` instead. Configuration string. It specifies things like requested fields and timestamp formats. If migrating from the logpull api, copy the url (full url or just the query string) of your call here, and logpush will keep on making this call for you, setting start and end times appropriately.
        /// </summary>
        [Output("logpullOptions")]
        public Output<string?> LogpullOptions { get; private set; } = null!;

        /// <summary>
        /// The maximum uncompressed file size of a batch of logs. This setting value must be between `5 MB` and `1 GB`, or `0` to disable it. Note that you cannot set a minimum file size; this means that log files may be much smaller than this batch size. This parameter is not available for jobs with `edge` as its kind.
        /// </summary>
        [Output("maxUploadBytes")]
        public Output<int?> MaxUploadBytes { get; private set; } = null!;

        /// <summary>
        /// The maximum interval in seconds for log batches. This setting must be between 30 and 300 seconds (5 minutes), or `0` to disable it. Note that you cannot specify a minimum interval for log batches; this means that log files may be sent in shorter intervals than this. This parameter is only used for jobs with `edge` as its kind.
        /// </summary>
        [Output("maxUploadIntervalSeconds")]
        public Output<int> MaxUploadIntervalSeconds { get; private set; } = null!;

        /// <summary>
        /// The maximum number of log lines per batch. This setting must be between 1000 and 1,000,000 lines, or `0` to disable it. Note that you cannot specify a minimum number of log lines per batch; this means that log files may contain many fewer lines than this. This parameter is not available for jobs with `edge` as its kind.
        /// </summary>
        [Output("maxUploadRecords")]
        public Output<int> MaxUploadRecords { get; private set; } = null!;

        /// <summary>
        /// Optional human readable job name. Not unique. Cloudflare suggests that you set this to a meaningful string, like the domain name, to make it easier to identify your job.
        /// </summary>
        [Output("name")]
        public Output<string?> Name { get; private set; } = null!;

        /// <summary>
        /// The structured replacement for `logpull_options`. When including this field, the `logpull_option` field will be ignored.
        /// </summary>
        [Output("outputOptions")]
        public Output<Outputs.LogpushJobOutputOptions> OutputOptions { get; private set; } = null!;

        /// <summary>
        /// Ownership challenge token to prove destination ownership.
        /// </summary>
        [Output("ownershipChallenge")]
        public Output<string?> OwnershipChallenge { get; private set; } = null!;

        /// <summary>
        /// The Zone ID to use for this endpoint. Mutually exclusive with the Account ID.
        /// </summary>
        [Output("zoneId")]
        public Output<string?> ZoneId { get; private set; } = null!;


        /// <summary>
        /// Create a LogpushJob resource with the given unique name, arguments, and options.
        /// </summary>
        ///
        /// <param name="name">The unique name of the resource</param>
        /// <param name="args">The arguments used to populate this resource's properties</param>
        /// <param name="options">A bag of options that control this resource's behavior</param>
        public LogpushJob(string name, LogpushJobArgs args, CustomResourceOptions? options = null)
            : base("cloudflare:index/logpushJob:LogpushJob", name, args ?? new LogpushJobArgs(), MakeResourceOptions(options, ""))
        {
        }

        private LogpushJob(string name, Input<string> id, LogpushJobState? state = null, CustomResourceOptions? options = null)
            : base("cloudflare:index/logpushJob:LogpushJob", name, state, MakeResourceOptions(options, id))
        {
        }

        private static CustomResourceOptions MakeResourceOptions(CustomResourceOptions? options, Input<string>? id)
        {
            var defaultOptions = new CustomResourceOptions
            {
                Version = Utilities.Version,
                AdditionalSecretOutputs =
                {
                    "ownershipChallenge",
                },
            };
            var merged = CustomResourceOptions.Merge(defaultOptions, options);
            // Override the ID if one was specified for consistency with other language SDKs.
            merged.Id = id ?? merged.Id;
            return merged;
        }
        /// <summary>
        /// Get an existing LogpushJob resource's state with the given name, ID, and optional extra
        /// properties used to qualify the lookup.
        /// </summary>
        ///
        /// <param name="name">The unique name of the resulting resource.</param>
        /// <param name="id">The unique provider ID of the resource to lookup.</param>
        /// <param name="state">Any extra arguments used during the lookup.</param>
        /// <param name="options">A bag of options that control this resource's behavior</param>
        public static LogpushJob Get(string name, Input<string> id, LogpushJobState? state = null, CustomResourceOptions? options = null)
        {
            return new LogpushJob(name, id, state, options);
        }
    }

    public sealed class LogpushJobArgs : global::Pulumi.ResourceArgs
    {
        /// <summary>
        /// The Account ID to use for this endpoint. Mutually exclusive with the Zone ID.
        /// </summary>
        [Input("accountId")]
        public Input<string>? AccountId { get; set; }

        /// <summary>
        /// Name of the dataset. A list of supported datasets can be found on the [Developer Docs](https://developers.cloudflare.com/logs/reference/log-fields/).
        /// Available values: "access*requests", "audit*logs", "biso*user*actions", "casb*findings", "device*posture*results", "dlp*forensic*copies", "dns*firewall*logs", "dns*logs", "email*security*alerts", "firewall*events", "gateway*dns", "gateway*http", "gateway*network", "http*requests", "magic*ids*detections", "nel*reports", "network*analytics*logs", "page*shield*events", "sinkhole*http*logs", "spectrum*events", "ssh*logs", "workers*trace*events", "zaraz*events", "zero*trust*network*sessions".
        /// </summary>
        [Input("dataset")]
        public Input<string>? Dataset { get; set; }

        /// <summary>
        /// Uniquely identifies a resource (such as an s3 bucket) where data will be pushed. Additional configuration parameters supported by the destination may be included.
        /// </summary>
        [Input("destinationConf", required: true)]
        public Input<string> DestinationConf { get; set; } = null!;

        /// <summary>
        /// Flag that indicates if the job is enabled.
        /// </summary>
        [Input("enabled")]
        public Input<bool>? Enabled { get; set; }

        /// <summary>
        /// The filters to select the events to include and/or remove from your logs. For more information, refer to [Filters](https://developers.cloudflare.com/logs/reference/filters/).
        /// </summary>
        [Input("filter")]
        public Input<string>? Filter { get; set; }

        /// <summary>
        /// This field is deprecated. Please use `max_upload_*` parameters instead. The frequency at which Cloudflare sends batches of logs to your destination. Setting frequency to high sends your logs in larger quantities of smaller files. Setting frequency to low sends logs in smaller quantities of larger files.
        /// Available values: "high", "low".
        /// </summary>
        [Input("frequency")]
        public Input<string>? Frequency { get; set; }

        /// <summary>
        /// The kind parameter (optional) is used to differentiate between Logpush and Edge Log Delivery jobs. Currently, Edge Log Delivery is only supported for the `http_requests` dataset.
        /// Available values: "edge".
        /// </summary>
        [Input("kind")]
        public Input<string>? Kind { get; set; }

        /// <summary>
        /// This field is deprecated. Use `output_options` instead. Configuration string. It specifies things like requested fields and timestamp formats. If migrating from the logpull api, copy the url (full url or just the query string) of your call here, and logpush will keep on making this call for you, setting start and end times appropriately.
        /// </summary>
        [Input("logpullOptions")]
        public Input<string>? LogpullOptions { get; set; }

        /// <summary>
        /// The maximum uncompressed file size of a batch of logs. This setting value must be between `5 MB` and `1 GB`, or `0` to disable it. Note that you cannot set a minimum file size; this means that log files may be much smaller than this batch size. This parameter is not available for jobs with `edge` as its kind.
        /// </summary>
        [Input("maxUploadBytes")]
        public Input<int>? MaxUploadBytes { get; set; }

        /// <summary>
        /// The maximum interval in seconds for log batches. This setting must be between 30 and 300 seconds (5 minutes), or `0` to disable it. Note that you cannot specify a minimum interval for log batches; this means that log files may be sent in shorter intervals than this. This parameter is only used for jobs with `edge` as its kind.
        /// </summary>
        [Input("maxUploadIntervalSeconds")]
        public Input<int>? MaxUploadIntervalSeconds { get; set; }

        /// <summary>
        /// The maximum number of log lines per batch. This setting must be between 1000 and 1,000,000 lines, or `0` to disable it. Note that you cannot specify a minimum number of log lines per batch; this means that log files may contain many fewer lines than this. This parameter is not available for jobs with `edge` as its kind.
        /// </summary>
        [Input("maxUploadRecords")]
        public Input<int>? MaxUploadRecords { get; set; }

        /// <summary>
        /// Optional human readable job name. Not unique. Cloudflare suggests that you set this to a meaningful string, like the domain name, to make it easier to identify your job.
        /// </summary>
        [Input("name")]
        public Input<string>? Name { get; set; }

        /// <summary>
        /// The structured replacement for `logpull_options`. When including this field, the `logpull_option` field will be ignored.
        /// </summary>
        [Input("outputOptions")]
        public Input<Inputs.LogpushJobOutputOptionsArgs>? OutputOptions { get; set; }

        [Input("ownershipChallenge")]
        private Input<string>? _ownershipChallenge;

        /// <summary>
        /// Ownership challenge token to prove destination ownership.
        /// </summary>
        public Input<string>? OwnershipChallenge
        {
            get => _ownershipChallenge;
            set
            {
                var emptySecret = Output.CreateSecret(0);
                _ownershipChallenge = Output.Tuple<Input<string>?, int>(value, emptySecret).Apply(t => t.Item1);
            }
        }

        /// <summary>
        /// The Zone ID to use for this endpoint. Mutually exclusive with the Account ID.
        /// </summary>
        [Input("zoneId")]
        public Input<string>? ZoneId { get; set; }

        public LogpushJobArgs()
        {
        }
        public static new LogpushJobArgs Empty => new LogpushJobArgs();
    }

    public sealed class LogpushJobState : global::Pulumi.ResourceArgs
    {
        /// <summary>
        /// The Account ID to use for this endpoint. Mutually exclusive with the Zone ID.
        /// </summary>
        [Input("accountId")]
        public Input<string>? AccountId { get; set; }

        /// <summary>
        /// Name of the dataset. A list of supported datasets can be found on the [Developer Docs](https://developers.cloudflare.com/logs/reference/log-fields/).
        /// Available values: "access*requests", "audit*logs", "biso*user*actions", "casb*findings", "device*posture*results", "dlp*forensic*copies", "dns*firewall*logs", "dns*logs", "email*security*alerts", "firewall*events", "gateway*dns", "gateway*http", "gateway*network", "http*requests", "magic*ids*detections", "nel*reports", "network*analytics*logs", "page*shield*events", "sinkhole*http*logs", "spectrum*events", "ssh*logs", "workers*trace*events", "zaraz*events", "zero*trust*network*sessions".
        /// </summary>
        [Input("dataset")]
        public Input<string>? Dataset { get; set; }

        /// <summary>
        /// Uniquely identifies a resource (such as an s3 bucket) where data will be pushed. Additional configuration parameters supported by the destination may be included.
        /// </summary>
        [Input("destinationConf")]
        public Input<string>? DestinationConf { get; set; }

        /// <summary>
        /// Flag that indicates if the job is enabled.
        /// </summary>
        [Input("enabled")]
        public Input<bool>? Enabled { get; set; }

        /// <summary>
        /// If not null, the job is currently failing. Failures are usually repetitive (example: no permissions to write to destination bucket). Only the last failure is recorded. On successful execution of a job the error*message and last*error are set to null.
        /// </summary>
        [Input("errorMessage")]
        public Input<string>? ErrorMessage { get; set; }

        /// <summary>
        /// The filters to select the events to include and/or remove from your logs. For more information, refer to [Filters](https://developers.cloudflare.com/logs/reference/filters/).
        /// </summary>
        [Input("filter")]
        public Input<string>? Filter { get; set; }

        /// <summary>
        /// This field is deprecated. Please use `max_upload_*` parameters instead. The frequency at which Cloudflare sends batches of logs to your destination. Setting frequency to high sends your logs in larger quantities of smaller files. Setting frequency to low sends logs in smaller quantities of larger files.
        /// Available values: "high", "low".
        /// </summary>
        [Input("frequency")]
        public Input<string>? Frequency { get; set; }

        /// <summary>
        /// The kind parameter (optional) is used to differentiate between Logpush and Edge Log Delivery jobs. Currently, Edge Log Delivery is only supported for the `http_requests` dataset.
        /// Available values: "edge".
        /// </summary>
        [Input("kind")]
        public Input<string>? Kind { get; set; }

        /// <summary>
        /// Records the last time for which logs have been successfully pushed. If the last successful push was for logs range 2018-07-23T10:00:00Z to 2018-07-23T10:01:00Z then the value of this field will be 2018-07-23T10:01:00Z. If the job has never run or has just been enabled and hasn't run yet then the field will be empty.
        /// </summary>
        [Input("lastComplete")]
        public Input<string>? LastComplete { get; set; }

        /// <summary>
        /// Records the last time the job failed. If not null, the job is currently failing. If null, the job has either never failed or has run successfully at least once since last failure. See also the error_message field.
        /// </summary>
        [Input("lastError")]
        public Input<string>? LastError { get; set; }

        /// <summary>
        /// This field is deprecated. Use `output_options` instead. Configuration string. It specifies things like requested fields and timestamp formats. If migrating from the logpull api, copy the url (full url or just the query string) of your call here, and logpush will keep on making this call for you, setting start and end times appropriately.
        /// </summary>
        [Input("logpullOptions")]
        public Input<string>? LogpullOptions { get; set; }

        /// <summary>
        /// The maximum uncompressed file size of a batch of logs. This setting value must be between `5 MB` and `1 GB`, or `0` to disable it. Note that you cannot set a minimum file size; this means that log files may be much smaller than this batch size. This parameter is not available for jobs with `edge` as its kind.
        /// </summary>
        [Input("maxUploadBytes")]
        public Input<int>? MaxUploadBytes { get; set; }

        /// <summary>
        /// The maximum interval in seconds for log batches. This setting must be between 30 and 300 seconds (5 minutes), or `0` to disable it. Note that you cannot specify a minimum interval for log batches; this means that log files may be sent in shorter intervals than this. This parameter is only used for jobs with `edge` as its kind.
        /// </summary>
        [Input("maxUploadIntervalSeconds")]
        public Input<int>? MaxUploadIntervalSeconds { get; set; }

        /// <summary>
        /// The maximum number of log lines per batch. This setting must be between 1000 and 1,000,000 lines, or `0` to disable it. Note that you cannot specify a minimum number of log lines per batch; this means that log files may contain many fewer lines than this. This parameter is not available for jobs with `edge` as its kind.
        /// </summary>
        [Input("maxUploadRecords")]
        public Input<int>? MaxUploadRecords { get; set; }

        /// <summary>
        /// Optional human readable job name. Not unique. Cloudflare suggests that you set this to a meaningful string, like the domain name, to make it easier to identify your job.
        /// </summary>
        [Input("name")]
        public Input<string>? Name { get; set; }

        /// <summary>
        /// The structured replacement for `logpull_options`. When including this field, the `logpull_option` field will be ignored.
        /// </summary>
        [Input("outputOptions")]
        public Input<Inputs.LogpushJobOutputOptionsGetArgs>? OutputOptions { get; set; }

        [Input("ownershipChallenge")]
        private Input<string>? _ownershipChallenge;

        /// <summary>
        /// Ownership challenge token to prove destination ownership.
        /// </summary>
        public Input<string>? OwnershipChallenge
        {
            get => _ownershipChallenge;
            set
            {
                var emptySecret = Output.CreateSecret(0);
                _ownershipChallenge = Output.Tuple<Input<string>?, int>(value, emptySecret).Apply(t => t.Item1);
            }
        }

        /// <summary>
        /// The Zone ID to use for this endpoint. Mutually exclusive with the Account ID.
        /// </summary>
        [Input("zoneId")]
        public Input<string>? ZoneId { get; set; }

        public LogpushJobState()
        {
        }
        public static new LogpushJobState Empty => new LogpushJobState();
    }
}
