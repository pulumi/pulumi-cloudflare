# coding=utf-8
# *** WARNING: this file was generated by pulumi-language-python. ***
# *** Do not edit by hand unless you're certain you know what you are doing! ***

import builtins as _builtins
import warnings
import sys
import pulumi
import pulumi.runtime
from typing import Any, Mapping, Optional, Sequence, Union, overload
if sys.version_info >= (3, 11):
    from typing import NotRequired, TypedDict, TypeAlias
else:
    from typing_extensions import NotRequired, TypedDict, TypeAlias
from . import _utilities
from . import outputs
from ._inputs import *

__all__ = [
    'GetAiSearchInstanceResult',
    'AwaitableGetAiSearchInstanceResult',
    'get_ai_search_instance',
    'get_ai_search_instance_output',
]

@pulumi.output_type
class GetAiSearchInstanceResult:
    """
    A collection of values returned by getAiSearchInstance.
    """
    def __init__(__self__, account_id=None, account_tag=None, ai_gateway_id=None, aisearch_model=None, cache=None, cache_threshold=None, chunk=None, chunk_overlap=None, chunk_size=None, created_at=None, created_by=None, custom_metadatas=None, embedding_model=None, enable=None, engine_version=None, filter=None, hybrid_search_enabled=None, id=None, internal_id=None, last_activity=None, max_num_results=None, metadata=None, modified_at=None, modified_by=None, paused=None, public_endpoint_id=None, public_endpoint_params=None, reranking=None, reranking_model=None, rewrite_model=None, rewrite_query=None, score_threshold=None, source=None, source_params=None, status=None, summarization=None, summarization_model=None, system_prompt_aisearch=None, system_prompt_index_summarization=None, system_prompt_rewrite_query=None, token_id=None, type=None, vectorize_active_namespace=None, vectorize_name=None):
        if account_id and not isinstance(account_id, str):
            raise TypeError("Expected argument 'account_id' to be a str")
        pulumi.set(__self__, "account_id", account_id)
        if account_tag and not isinstance(account_tag, str):
            raise TypeError("Expected argument 'account_tag' to be a str")
        pulumi.set(__self__, "account_tag", account_tag)
        if ai_gateway_id and not isinstance(ai_gateway_id, str):
            raise TypeError("Expected argument 'ai_gateway_id' to be a str")
        pulumi.set(__self__, "ai_gateway_id", ai_gateway_id)
        if aisearch_model and not isinstance(aisearch_model, str):
            raise TypeError("Expected argument 'aisearch_model' to be a str")
        pulumi.set(__self__, "aisearch_model", aisearch_model)
        if cache and not isinstance(cache, bool):
            raise TypeError("Expected argument 'cache' to be a bool")
        pulumi.set(__self__, "cache", cache)
        if cache_threshold and not isinstance(cache_threshold, str):
            raise TypeError("Expected argument 'cache_threshold' to be a str")
        pulumi.set(__self__, "cache_threshold", cache_threshold)
        if chunk and not isinstance(chunk, bool):
            raise TypeError("Expected argument 'chunk' to be a bool")
        pulumi.set(__self__, "chunk", chunk)
        if chunk_overlap and not isinstance(chunk_overlap, int):
            raise TypeError("Expected argument 'chunk_overlap' to be a int")
        pulumi.set(__self__, "chunk_overlap", chunk_overlap)
        if chunk_size and not isinstance(chunk_size, int):
            raise TypeError("Expected argument 'chunk_size' to be a int")
        pulumi.set(__self__, "chunk_size", chunk_size)
        if created_at and not isinstance(created_at, str):
            raise TypeError("Expected argument 'created_at' to be a str")
        pulumi.set(__self__, "created_at", created_at)
        if created_by and not isinstance(created_by, str):
            raise TypeError("Expected argument 'created_by' to be a str")
        pulumi.set(__self__, "created_by", created_by)
        if custom_metadatas and not isinstance(custom_metadatas, list):
            raise TypeError("Expected argument 'custom_metadatas' to be a list")
        pulumi.set(__self__, "custom_metadatas", custom_metadatas)
        if embedding_model and not isinstance(embedding_model, str):
            raise TypeError("Expected argument 'embedding_model' to be a str")
        pulumi.set(__self__, "embedding_model", embedding_model)
        if enable and not isinstance(enable, bool):
            raise TypeError("Expected argument 'enable' to be a bool")
        pulumi.set(__self__, "enable", enable)
        if engine_version and not isinstance(engine_version, float):
            raise TypeError("Expected argument 'engine_version' to be a float")
        pulumi.set(__self__, "engine_version", engine_version)
        if filter and not isinstance(filter, dict):
            raise TypeError("Expected argument 'filter' to be a dict")
        pulumi.set(__self__, "filter", filter)
        if hybrid_search_enabled and not isinstance(hybrid_search_enabled, bool):
            raise TypeError("Expected argument 'hybrid_search_enabled' to be a bool")
        pulumi.set(__self__, "hybrid_search_enabled", hybrid_search_enabled)
        if id and not isinstance(id, str):
            raise TypeError("Expected argument 'id' to be a str")
        pulumi.set(__self__, "id", id)
        if internal_id and not isinstance(internal_id, str):
            raise TypeError("Expected argument 'internal_id' to be a str")
        pulumi.set(__self__, "internal_id", internal_id)
        if last_activity and not isinstance(last_activity, str):
            raise TypeError("Expected argument 'last_activity' to be a str")
        pulumi.set(__self__, "last_activity", last_activity)
        if max_num_results and not isinstance(max_num_results, int):
            raise TypeError("Expected argument 'max_num_results' to be a int")
        pulumi.set(__self__, "max_num_results", max_num_results)
        if metadata and not isinstance(metadata, dict):
            raise TypeError("Expected argument 'metadata' to be a dict")
        pulumi.set(__self__, "metadata", metadata)
        if modified_at and not isinstance(modified_at, str):
            raise TypeError("Expected argument 'modified_at' to be a str")
        pulumi.set(__self__, "modified_at", modified_at)
        if modified_by and not isinstance(modified_by, str):
            raise TypeError("Expected argument 'modified_by' to be a str")
        pulumi.set(__self__, "modified_by", modified_by)
        if paused and not isinstance(paused, bool):
            raise TypeError("Expected argument 'paused' to be a bool")
        pulumi.set(__self__, "paused", paused)
        if public_endpoint_id and not isinstance(public_endpoint_id, str):
            raise TypeError("Expected argument 'public_endpoint_id' to be a str")
        pulumi.set(__self__, "public_endpoint_id", public_endpoint_id)
        if public_endpoint_params and not isinstance(public_endpoint_params, dict):
            raise TypeError("Expected argument 'public_endpoint_params' to be a dict")
        pulumi.set(__self__, "public_endpoint_params", public_endpoint_params)
        if reranking and not isinstance(reranking, bool):
            raise TypeError("Expected argument 'reranking' to be a bool")
        pulumi.set(__self__, "reranking", reranking)
        if reranking_model and not isinstance(reranking_model, str):
            raise TypeError("Expected argument 'reranking_model' to be a str")
        pulumi.set(__self__, "reranking_model", reranking_model)
        if rewrite_model and not isinstance(rewrite_model, str):
            raise TypeError("Expected argument 'rewrite_model' to be a str")
        pulumi.set(__self__, "rewrite_model", rewrite_model)
        if rewrite_query and not isinstance(rewrite_query, bool):
            raise TypeError("Expected argument 'rewrite_query' to be a bool")
        pulumi.set(__self__, "rewrite_query", rewrite_query)
        if score_threshold and not isinstance(score_threshold, float):
            raise TypeError("Expected argument 'score_threshold' to be a float")
        pulumi.set(__self__, "score_threshold", score_threshold)
        if source and not isinstance(source, str):
            raise TypeError("Expected argument 'source' to be a str")
        pulumi.set(__self__, "source", source)
        if source_params and not isinstance(source_params, dict):
            raise TypeError("Expected argument 'source_params' to be a dict")
        pulumi.set(__self__, "source_params", source_params)
        if status and not isinstance(status, str):
            raise TypeError("Expected argument 'status' to be a str")
        pulumi.set(__self__, "status", status)
        if summarization and not isinstance(summarization, bool):
            raise TypeError("Expected argument 'summarization' to be a bool")
        pulumi.set(__self__, "summarization", summarization)
        if summarization_model and not isinstance(summarization_model, str):
            raise TypeError("Expected argument 'summarization_model' to be a str")
        pulumi.set(__self__, "summarization_model", summarization_model)
        if system_prompt_aisearch and not isinstance(system_prompt_aisearch, str):
            raise TypeError("Expected argument 'system_prompt_aisearch' to be a str")
        pulumi.set(__self__, "system_prompt_aisearch", system_prompt_aisearch)
        if system_prompt_index_summarization and not isinstance(system_prompt_index_summarization, str):
            raise TypeError("Expected argument 'system_prompt_index_summarization' to be a str")
        pulumi.set(__self__, "system_prompt_index_summarization", system_prompt_index_summarization)
        if system_prompt_rewrite_query and not isinstance(system_prompt_rewrite_query, str):
            raise TypeError("Expected argument 'system_prompt_rewrite_query' to be a str")
        pulumi.set(__self__, "system_prompt_rewrite_query", system_prompt_rewrite_query)
        if token_id and not isinstance(token_id, str):
            raise TypeError("Expected argument 'token_id' to be a str")
        pulumi.set(__self__, "token_id", token_id)
        if type and not isinstance(type, str):
            raise TypeError("Expected argument 'type' to be a str")
        pulumi.set(__self__, "type", type)
        if vectorize_active_namespace and not isinstance(vectorize_active_namespace, str):
            raise TypeError("Expected argument 'vectorize_active_namespace' to be a str")
        pulumi.set(__self__, "vectorize_active_namespace", vectorize_active_namespace)
        if vectorize_name and not isinstance(vectorize_name, str):
            raise TypeError("Expected argument 'vectorize_name' to be a str")
        pulumi.set(__self__, "vectorize_name", vectorize_name)

    @_builtins.property
    @pulumi.getter(name="accountId")
    def account_id(self) -> _builtins.str:
        return pulumi.get(self, "account_id")

    @_builtins.property
    @pulumi.getter(name="accountTag")
    def account_tag(self) -> _builtins.str:
        return pulumi.get(self, "account_tag")

    @_builtins.property
    @pulumi.getter(name="aiGatewayId")
    def ai_gateway_id(self) -> _builtins.str:
        return pulumi.get(self, "ai_gateway_id")

    @_builtins.property
    @pulumi.getter(name="aisearchModel")
    def aisearch_model(self) -> _builtins.str:
        """
        Available values: "@cf/meta/llama-3.3-70b-instruct-fp8-fast", "@cf/meta/llama-3.1-8b-instruct-fast", "@cf/meta/llama-3.1-8b-instruct-fp8", "@cf/meta/llama-4-scout-17b-16e-instruct", "@cf/qwen/qwen3-30b-a3b-fp8", "@cf/deepseek-ai/deepseek-r1-distill-qwen-32b", "@cf/moonshotai/kimi-k2-instruct", "anthropic/claude-3-7-sonnet", "anthropic/claude-sonnet-4", "anthropic/claude-opus-4", "anthropic/claude-3-5-haiku", "cerebras/qwen-3-235b-a22b-instruct", "cerebras/qwen-3-235b-a22b-thinking", "cerebras/llama-3.3-70b", "cerebras/llama-4-maverick-17b-128e-instruct", "cerebras/llama-4-scout-17b-16e-instruct", "cerebras/gpt-oss-120b", "google-ai-studio/gemini-2.5-flash", "google-ai-studio/gemini-2.5-pro", "grok/grok-4", "groq/llama-3.3-70b-versatile", "groq/llama-3.1-8b-instant", "openai/gpt-5", "openai/gpt-5-mini", "openai/gpt-5-nano", "".
        """
        return pulumi.get(self, "aisearch_model")

    @_builtins.property
    @pulumi.getter
    def cache(self) -> _builtins.bool:
        return pulumi.get(self, "cache")

    @_builtins.property
    @pulumi.getter(name="cacheThreshold")
    def cache_threshold(self) -> _builtins.str:
        """
        Available values: "super*strict*match", "close*enough", "flexible*friend", "anything_goes".
        """
        return pulumi.get(self, "cache_threshold")

    @_builtins.property
    @pulumi.getter
    def chunk(self) -> _builtins.bool:
        return pulumi.get(self, "chunk")

    @_builtins.property
    @pulumi.getter(name="chunkOverlap")
    def chunk_overlap(self) -> _builtins.int:
        return pulumi.get(self, "chunk_overlap")

    @_builtins.property
    @pulumi.getter(name="chunkSize")
    def chunk_size(self) -> _builtins.int:
        return pulumi.get(self, "chunk_size")

    @_builtins.property
    @pulumi.getter(name="createdAt")
    def created_at(self) -> _builtins.str:
        return pulumi.get(self, "created_at")

    @_builtins.property
    @pulumi.getter(name="createdBy")
    def created_by(self) -> _builtins.str:
        return pulumi.get(self, "created_by")

    @_builtins.property
    @pulumi.getter(name="customMetadatas")
    def custom_metadatas(self) -> Sequence['outputs.GetAiSearchInstanceCustomMetadataResult']:
        return pulumi.get(self, "custom_metadatas")

    @_builtins.property
    @pulumi.getter(name="embeddingModel")
    def embedding_model(self) -> _builtins.str:
        """
        Available values: "@cf/qwen/qwen3-embedding-0.6b", "@cf/baai/bge-m3", "@cf/baai/bge-large-en-v1.5", "@cf/google/embeddinggemma-300m", "google-ai-studio/gemini-embedding-001", "openai/text-embedding-3-small", "openai/text-embedding-3-large", "".
        """
        return pulumi.get(self, "embedding_model")

    @_builtins.property
    @pulumi.getter
    def enable(self) -> _builtins.bool:
        return pulumi.get(self, "enable")

    @_builtins.property
    @pulumi.getter(name="engineVersion")
    def engine_version(self) -> _builtins.float:
        return pulumi.get(self, "engine_version")

    @_builtins.property
    @pulumi.getter
    def filter(self) -> Optional['outputs.GetAiSearchInstanceFilterResult']:
        return pulumi.get(self, "filter")

    @_builtins.property
    @pulumi.getter(name="hybridSearchEnabled")
    def hybrid_search_enabled(self) -> _builtins.bool:
        return pulumi.get(self, "hybrid_search_enabled")

    @_builtins.property
    @pulumi.getter
    def id(self) -> _builtins.str:
        """
        Use your AI Search ID.
        """
        return pulumi.get(self, "id")

    @_builtins.property
    @pulumi.getter(name="internalId")
    def internal_id(self) -> _builtins.str:
        return pulumi.get(self, "internal_id")

    @_builtins.property
    @pulumi.getter(name="lastActivity")
    def last_activity(self) -> _builtins.str:
        return pulumi.get(self, "last_activity")

    @_builtins.property
    @pulumi.getter(name="maxNumResults")
    def max_num_results(self) -> _builtins.int:
        return pulumi.get(self, "max_num_results")

    @_builtins.property
    @pulumi.getter
    def metadata(self) -> 'outputs.GetAiSearchInstanceMetadataResult':
        return pulumi.get(self, "metadata")

    @_builtins.property
    @pulumi.getter(name="modifiedAt")
    def modified_at(self) -> _builtins.str:
        return pulumi.get(self, "modified_at")

    @_builtins.property
    @pulumi.getter(name="modifiedBy")
    def modified_by(self) -> _builtins.str:
        return pulumi.get(self, "modified_by")

    @_builtins.property
    @pulumi.getter
    def paused(self) -> _builtins.bool:
        return pulumi.get(self, "paused")

    @_builtins.property
    @pulumi.getter(name="publicEndpointId")
    def public_endpoint_id(self) -> _builtins.str:
        return pulumi.get(self, "public_endpoint_id")

    @_builtins.property
    @pulumi.getter(name="publicEndpointParams")
    def public_endpoint_params(self) -> 'outputs.GetAiSearchInstancePublicEndpointParamsResult':
        return pulumi.get(self, "public_endpoint_params")

    @_builtins.property
    @pulumi.getter
    def reranking(self) -> _builtins.bool:
        return pulumi.get(self, "reranking")

    @_builtins.property
    @pulumi.getter(name="rerankingModel")
    def reranking_model(self) -> _builtins.str:
        """
        Available values: "@cf/baai/bge-reranker-base", "".
        """
        return pulumi.get(self, "reranking_model")

    @_builtins.property
    @pulumi.getter(name="rewriteModel")
    def rewrite_model(self) -> _builtins.str:
        """
        Available values: "@cf/meta/llama-3.3-70b-instruct-fp8-fast", "@cf/meta/llama-3.1-8b-instruct-fast", "@cf/meta/llama-3.1-8b-instruct-fp8", "@cf/meta/llama-4-scout-17b-16e-instruct", "@cf/qwen/qwen3-30b-a3b-fp8", "@cf/deepseek-ai/deepseek-r1-distill-qwen-32b", "@cf/moonshotai/kimi-k2-instruct", "anthropic/claude-3-7-sonnet", "anthropic/claude-sonnet-4", "anthropic/claude-opus-4", "anthropic/claude-3-5-haiku", "cerebras/qwen-3-235b-a22b-instruct", "cerebras/qwen-3-235b-a22b-thinking", "cerebras/llama-3.3-70b", "cerebras/llama-4-maverick-17b-128e-instruct", "cerebras/llama-4-scout-17b-16e-instruct", "cerebras/gpt-oss-120b", "google-ai-studio/gemini-2.5-flash", "google-ai-studio/gemini-2.5-pro", "grok/grok-4", "groq/llama-3.3-70b-versatile", "groq/llama-3.1-8b-instant", "openai/gpt-5", "openai/gpt-5-mini", "openai/gpt-5-nano", "".
        """
        return pulumi.get(self, "rewrite_model")

    @_builtins.property
    @pulumi.getter(name="rewriteQuery")
    def rewrite_query(self) -> _builtins.bool:
        return pulumi.get(self, "rewrite_query")

    @_builtins.property
    @pulumi.getter(name="scoreThreshold")
    def score_threshold(self) -> _builtins.float:
        return pulumi.get(self, "score_threshold")

    @_builtins.property
    @pulumi.getter
    def source(self) -> _builtins.str:
        return pulumi.get(self, "source")

    @_builtins.property
    @pulumi.getter(name="sourceParams")
    def source_params(self) -> 'outputs.GetAiSearchInstanceSourceParamsResult':
        return pulumi.get(self, "source_params")

    @_builtins.property
    @pulumi.getter
    def status(self) -> _builtins.str:
        return pulumi.get(self, "status")

    @_builtins.property
    @pulumi.getter
    def summarization(self) -> _builtins.bool:
        return pulumi.get(self, "summarization")

    @_builtins.property
    @pulumi.getter(name="summarizationModel")
    def summarization_model(self) -> _builtins.str:
        """
        Available values: "@cf/meta/llama-3.3-70b-instruct-fp8-fast", "@cf/meta/llama-3.1-8b-instruct-fast", "@cf/meta/llama-3.1-8b-instruct-fp8", "@cf/meta/llama-4-scout-17b-16e-instruct", "@cf/qwen/qwen3-30b-a3b-fp8", "@cf/deepseek-ai/deepseek-r1-distill-qwen-32b", "@cf/moonshotai/kimi-k2-instruct", "anthropic/claude-3-7-sonnet", "anthropic/claude-sonnet-4", "anthropic/claude-opus-4", "anthropic/claude-3-5-haiku", "cerebras/qwen-3-235b-a22b-instruct", "cerebras/qwen-3-235b-a22b-thinking", "cerebras/llama-3.3-70b", "cerebras/llama-4-maverick-17b-128e-instruct", "cerebras/llama-4-scout-17b-16e-instruct", "cerebras/gpt-oss-120b", "google-ai-studio/gemini-2.5-flash", "google-ai-studio/gemini-2.5-pro", "grok/grok-4", "groq/llama-3.3-70b-versatile", "groq/llama-3.1-8b-instant", "openai/gpt-5", "openai/gpt-5-mini", "openai/gpt-5-nano", "".
        """
        return pulumi.get(self, "summarization_model")

    @_builtins.property
    @pulumi.getter(name="systemPromptAisearch")
    def system_prompt_aisearch(self) -> _builtins.str:
        return pulumi.get(self, "system_prompt_aisearch")

    @_builtins.property
    @pulumi.getter(name="systemPromptIndexSummarization")
    def system_prompt_index_summarization(self) -> _builtins.str:
        return pulumi.get(self, "system_prompt_index_summarization")

    @_builtins.property
    @pulumi.getter(name="systemPromptRewriteQuery")
    def system_prompt_rewrite_query(self) -> _builtins.str:
        return pulumi.get(self, "system_prompt_rewrite_query")

    @_builtins.property
    @pulumi.getter(name="tokenId")
    def token_id(self) -> _builtins.str:
        return pulumi.get(self, "token_id")

    @_builtins.property
    @pulumi.getter
    def type(self) -> _builtins.str:
        """
        Available values: "r2", "web-crawler".
        """
        return pulumi.get(self, "type")

    @_builtins.property
    @pulumi.getter(name="vectorizeActiveNamespace")
    def vectorize_active_namespace(self) -> _builtins.str:
        return pulumi.get(self, "vectorize_active_namespace")

    @_builtins.property
    @pulumi.getter(name="vectorizeName")
    def vectorize_name(self) -> _builtins.str:
        return pulumi.get(self, "vectorize_name")


class AwaitableGetAiSearchInstanceResult(GetAiSearchInstanceResult):
    # pylint: disable=using-constant-test
    def __await__(self):
        if False:
            yield self
        return GetAiSearchInstanceResult(
            account_id=self.account_id,
            account_tag=self.account_tag,
            ai_gateway_id=self.ai_gateway_id,
            aisearch_model=self.aisearch_model,
            cache=self.cache,
            cache_threshold=self.cache_threshold,
            chunk=self.chunk,
            chunk_overlap=self.chunk_overlap,
            chunk_size=self.chunk_size,
            created_at=self.created_at,
            created_by=self.created_by,
            custom_metadatas=self.custom_metadatas,
            embedding_model=self.embedding_model,
            enable=self.enable,
            engine_version=self.engine_version,
            filter=self.filter,
            hybrid_search_enabled=self.hybrid_search_enabled,
            id=self.id,
            internal_id=self.internal_id,
            last_activity=self.last_activity,
            max_num_results=self.max_num_results,
            metadata=self.metadata,
            modified_at=self.modified_at,
            modified_by=self.modified_by,
            paused=self.paused,
            public_endpoint_id=self.public_endpoint_id,
            public_endpoint_params=self.public_endpoint_params,
            reranking=self.reranking,
            reranking_model=self.reranking_model,
            rewrite_model=self.rewrite_model,
            rewrite_query=self.rewrite_query,
            score_threshold=self.score_threshold,
            source=self.source,
            source_params=self.source_params,
            status=self.status,
            summarization=self.summarization,
            summarization_model=self.summarization_model,
            system_prompt_aisearch=self.system_prompt_aisearch,
            system_prompt_index_summarization=self.system_prompt_index_summarization,
            system_prompt_rewrite_query=self.system_prompt_rewrite_query,
            token_id=self.token_id,
            type=self.type,
            vectorize_active_namespace=self.vectorize_active_namespace,
            vectorize_name=self.vectorize_name)


def get_ai_search_instance(account_id: Optional[_builtins.str] = None,
                           filter: Optional[Union['GetAiSearchInstanceFilterArgs', 'GetAiSearchInstanceFilterArgsDict']] = None,
                           id: Optional[_builtins.str] = None,
                           opts: Optional[pulumi.InvokeOptions] = None) -> AwaitableGetAiSearchInstanceResult:
    """
    Use this data source to access information about an existing resource.

    :param _builtins.str id: Use your AI Search ID.
    """
    __args__ = dict()
    __args__['accountId'] = account_id
    __args__['filter'] = filter
    __args__['id'] = id
    opts = pulumi.InvokeOptions.merge(_utilities.get_invoke_opts_defaults(), opts)
    __ret__ = pulumi.runtime.invoke('cloudflare:index/getAiSearchInstance:getAiSearchInstance', __args__, opts=opts, typ=GetAiSearchInstanceResult).value

    return AwaitableGetAiSearchInstanceResult(
        account_id=pulumi.get(__ret__, 'account_id'),
        account_tag=pulumi.get(__ret__, 'account_tag'),
        ai_gateway_id=pulumi.get(__ret__, 'ai_gateway_id'),
        aisearch_model=pulumi.get(__ret__, 'aisearch_model'),
        cache=pulumi.get(__ret__, 'cache'),
        cache_threshold=pulumi.get(__ret__, 'cache_threshold'),
        chunk=pulumi.get(__ret__, 'chunk'),
        chunk_overlap=pulumi.get(__ret__, 'chunk_overlap'),
        chunk_size=pulumi.get(__ret__, 'chunk_size'),
        created_at=pulumi.get(__ret__, 'created_at'),
        created_by=pulumi.get(__ret__, 'created_by'),
        custom_metadatas=pulumi.get(__ret__, 'custom_metadatas'),
        embedding_model=pulumi.get(__ret__, 'embedding_model'),
        enable=pulumi.get(__ret__, 'enable'),
        engine_version=pulumi.get(__ret__, 'engine_version'),
        filter=pulumi.get(__ret__, 'filter'),
        hybrid_search_enabled=pulumi.get(__ret__, 'hybrid_search_enabled'),
        id=pulumi.get(__ret__, 'id'),
        internal_id=pulumi.get(__ret__, 'internal_id'),
        last_activity=pulumi.get(__ret__, 'last_activity'),
        max_num_results=pulumi.get(__ret__, 'max_num_results'),
        metadata=pulumi.get(__ret__, 'metadata'),
        modified_at=pulumi.get(__ret__, 'modified_at'),
        modified_by=pulumi.get(__ret__, 'modified_by'),
        paused=pulumi.get(__ret__, 'paused'),
        public_endpoint_id=pulumi.get(__ret__, 'public_endpoint_id'),
        public_endpoint_params=pulumi.get(__ret__, 'public_endpoint_params'),
        reranking=pulumi.get(__ret__, 'reranking'),
        reranking_model=pulumi.get(__ret__, 'reranking_model'),
        rewrite_model=pulumi.get(__ret__, 'rewrite_model'),
        rewrite_query=pulumi.get(__ret__, 'rewrite_query'),
        score_threshold=pulumi.get(__ret__, 'score_threshold'),
        source=pulumi.get(__ret__, 'source'),
        source_params=pulumi.get(__ret__, 'source_params'),
        status=pulumi.get(__ret__, 'status'),
        summarization=pulumi.get(__ret__, 'summarization'),
        summarization_model=pulumi.get(__ret__, 'summarization_model'),
        system_prompt_aisearch=pulumi.get(__ret__, 'system_prompt_aisearch'),
        system_prompt_index_summarization=pulumi.get(__ret__, 'system_prompt_index_summarization'),
        system_prompt_rewrite_query=pulumi.get(__ret__, 'system_prompt_rewrite_query'),
        token_id=pulumi.get(__ret__, 'token_id'),
        type=pulumi.get(__ret__, 'type'),
        vectorize_active_namespace=pulumi.get(__ret__, 'vectorize_active_namespace'),
        vectorize_name=pulumi.get(__ret__, 'vectorize_name'))
def get_ai_search_instance_output(account_id: Optional[pulumi.Input[_builtins.str]] = None,
                                  filter: Optional[pulumi.Input[Optional[Union['GetAiSearchInstanceFilterArgs', 'GetAiSearchInstanceFilterArgsDict']]]] = None,
                                  id: Optional[pulumi.Input[Optional[_builtins.str]]] = None,
                                  opts: Optional[Union[pulumi.InvokeOptions, pulumi.InvokeOutputOptions]] = None) -> pulumi.Output[GetAiSearchInstanceResult]:
    """
    Use this data source to access information about an existing resource.

    :param _builtins.str id: Use your AI Search ID.
    """
    __args__ = dict()
    __args__['accountId'] = account_id
    __args__['filter'] = filter
    __args__['id'] = id
    opts = pulumi.InvokeOutputOptions.merge(_utilities.get_invoke_opts_defaults(), opts)
    __ret__ = pulumi.runtime.invoke_output('cloudflare:index/getAiSearchInstance:getAiSearchInstance', __args__, opts=opts, typ=GetAiSearchInstanceResult)
    return __ret__.apply(lambda __response__: GetAiSearchInstanceResult(
        account_id=pulumi.get(__response__, 'account_id'),
        account_tag=pulumi.get(__response__, 'account_tag'),
        ai_gateway_id=pulumi.get(__response__, 'ai_gateway_id'),
        aisearch_model=pulumi.get(__response__, 'aisearch_model'),
        cache=pulumi.get(__response__, 'cache'),
        cache_threshold=pulumi.get(__response__, 'cache_threshold'),
        chunk=pulumi.get(__response__, 'chunk'),
        chunk_overlap=pulumi.get(__response__, 'chunk_overlap'),
        chunk_size=pulumi.get(__response__, 'chunk_size'),
        created_at=pulumi.get(__response__, 'created_at'),
        created_by=pulumi.get(__response__, 'created_by'),
        custom_metadatas=pulumi.get(__response__, 'custom_metadatas'),
        embedding_model=pulumi.get(__response__, 'embedding_model'),
        enable=pulumi.get(__response__, 'enable'),
        engine_version=pulumi.get(__response__, 'engine_version'),
        filter=pulumi.get(__response__, 'filter'),
        hybrid_search_enabled=pulumi.get(__response__, 'hybrid_search_enabled'),
        id=pulumi.get(__response__, 'id'),
        internal_id=pulumi.get(__response__, 'internal_id'),
        last_activity=pulumi.get(__response__, 'last_activity'),
        max_num_results=pulumi.get(__response__, 'max_num_results'),
        metadata=pulumi.get(__response__, 'metadata'),
        modified_at=pulumi.get(__response__, 'modified_at'),
        modified_by=pulumi.get(__response__, 'modified_by'),
        paused=pulumi.get(__response__, 'paused'),
        public_endpoint_id=pulumi.get(__response__, 'public_endpoint_id'),
        public_endpoint_params=pulumi.get(__response__, 'public_endpoint_params'),
        reranking=pulumi.get(__response__, 'reranking'),
        reranking_model=pulumi.get(__response__, 'reranking_model'),
        rewrite_model=pulumi.get(__response__, 'rewrite_model'),
        rewrite_query=pulumi.get(__response__, 'rewrite_query'),
        score_threshold=pulumi.get(__response__, 'score_threshold'),
        source=pulumi.get(__response__, 'source'),
        source_params=pulumi.get(__response__, 'source_params'),
        status=pulumi.get(__response__, 'status'),
        summarization=pulumi.get(__response__, 'summarization'),
        summarization_model=pulumi.get(__response__, 'summarization_model'),
        system_prompt_aisearch=pulumi.get(__response__, 'system_prompt_aisearch'),
        system_prompt_index_summarization=pulumi.get(__response__, 'system_prompt_index_summarization'),
        system_prompt_rewrite_query=pulumi.get(__response__, 'system_prompt_rewrite_query'),
        token_id=pulumi.get(__response__, 'token_id'),
        type=pulumi.get(__response__, 'type'),
        vectorize_active_namespace=pulumi.get(__response__, 'vectorize_active_namespace'),
        vectorize_name=pulumi.get(__response__, 'vectorize_name')))
